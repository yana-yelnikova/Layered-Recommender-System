{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5aebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6e690",
   "metadata": {},
   "source": [
    "Adding geo-data to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3b0f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New columns have been added successfully! ✅\n",
      "     city                  district     neighborhood\n",
      "0  Berlin                     Mitte            Mitte\n",
      "1  Berlin                     Mitte            Mitte\n",
      "2  Berlin  Friedrichshain-Kreuzberg   Friedrichshain\n",
      "3  Berlin  Friedrichshain-Kreuzberg        Kreuzberg\n",
      "4  Berlin                    Pankow  Prenzlauer Berg\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Your Data ---\n",
    "\n",
    "# Path to the CSV file we are enriching\n",
    "csv_path = Path('../clean/night_clubs_clean.csv')\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Path to the GeoJSON file (in the same 'scripts' folder)\n",
    "geojson_path = 'lor_ortsteile.geojson'\n",
    "gdf_polygons = gpd.read_file(geojson_path)\n",
    "\n",
    "\n",
    "# --- 2. Create GeoDataFrames ---\n",
    "\n",
    "# Convert your DataFrame of post offices into a GeoDataFrame\n",
    "gdf_points = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Ensure both GeoDataFrames use the same Coordinate Reference System (CRS)\n",
    "gdf_polygons = gdf_polygons.to_crs(gdf_points.crs)\n",
    "\n",
    "\n",
    "# --- 3. Perform the Spatial Join ---\n",
    "\n",
    "# This finds which polygon (neighborhood) each point is in\n",
    "gdf_joined = gpd.sjoin(gdf_points, gdf_polygons, how=\"left\", predicate='within')\n",
    "\n",
    "\n",
    "# --- 4. Add the New Columns to Your Original DataFrame ---\n",
    "\n",
    "# We use the final column names we identified\n",
    "district_col_name = 'BEZIRK'\n",
    "neighborhood_col_name = 'OTEIL'\n",
    "\n",
    "# Add the new columns from the joined data back to your original DataFrame\n",
    "df['district'] = gdf_joined[district_col_name].reset_index(drop=True)\n",
    "df['neighborhood'] = gdf_joined[neighborhood_col_name].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- 5. Check the Result ---\n",
    "print(\"New columns have been added successfully! ✅\")\n",
    "# The redundant 'neighborhood_id' column has been removed from the check\n",
    "print(df[['city', 'district', 'neighborhood']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b5ae72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 142 entries, 0 to 141\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      142 non-null    object \n",
      " 1   club_name               141 non-null    object \n",
      " 2   phone                   59 non-null     object \n",
      " 3   website                 100 non-null    object \n",
      " 4   wheelchair              89 non-null     object \n",
      " 5   email                   18 non-null     object \n",
      " 6   toilets_wheelchair      36 non-null     object \n",
      " 7   wheelchair_description  11 non-null     object \n",
      " 8   city                    135 non-null    object \n",
      " 9   house_num               108 non-null    object \n",
      " 10  postcode                140 non-null    float64\n",
      " 11  street                  141 non-null    object \n",
      " 12  suburb                  114 non-null    object \n",
      " 13  opening_hours           53 non-null     object \n",
      " 14  live_music              10 non-null     object \n",
      " 15  longitude               142 non-null    float64\n",
      " 16  latitude                142 non-null    float64\n",
      " 17  district                142 non-null    object \n",
      " 18  neighborhood            142 non-null    object \n",
      "dtypes: float64(3), object(16)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06124841",
   "metadata": {},
   "source": [
    "Now I need to check that all clubs are within Berlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3642ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All 142 points are correctly located within the Berlin boundaries.\n"
     ]
    }
   ],
   "source": [
    "from shapely.ops import unary_union\n",
    "import geopandas as gpd # Import in case this is in a new cell\n",
    "\n",
    "# --- 1. Create a single \"Berlin\" polygon ---\n",
    "# We use 'gdf_polygons', which you already loaded and projected\n",
    "berlin_boundary = gpd.GeoSeries(unary_union(gdf_polygons.geometry), crs=gdf_polygons.crs)\n",
    "\n",
    "# --- 2. Perform the check ---\n",
    "# We use 'gdf_points', which you already created\n",
    "# .within() checks if each point is inside the berlin_boundary\n",
    "is_inside_berlin = gdf_points.within(berlin_boundary.geometry[0])\n",
    "\n",
    "# --- 3. Report the results ---\n",
    "num_outside = (~is_inside_berlin).sum() # ~ inverts True/False, counting the Falses (those outside)\n",
    "\n",
    "if num_outside == 0:\n",
    "    print(\"✅ All 142 points are correctly located within the Berlin boundaries.\")\n",
    "else:\n",
    "    print(f\"⚠️ Warning: Found {num_outside} point(s) outside the Berlin boundaries.\")\n",
    "    \n",
    "    # (Optional) Show the rows that are outside\n",
    "    # We use the original 'df' for a clean text report\n",
    "    print(\"\\nClubs located outside Berlin:\")\n",
    "    print(df[~is_inside_berlin][['club_name', 'street', 'city', 'latitude', 'longitude']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0263e9e",
   "metadata": {},
   "source": [
    "As all clubs are within Berlin, I'll fill missing values in the 'city' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a4a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city'] = df['city'].fillna('Berlin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4170c1a",
   "metadata": {},
   "source": [
    "Now we need to add a column district_id and neighborhood_id from database tables districts.csv and neighborhoods.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2fd9f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Districts Table Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   district_id  12 non-null     int64 \n",
      " 1   district     12 non-null     object\n",
      " 2   geometry     12 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 420.0+ bytes\n",
      "\n",
      "--- Districts Table Head ---\n",
      "   district_id                    district  \\\n",
      "0     11012012               Reinickendorf   \n",
      "1     11004004  Charlottenburg-Wilmersdorf   \n",
      "2     11009009            Treptow-Köpenick   \n",
      "3     11003003                      Pankow   \n",
      "4     11008008                    Neukölln   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((13.320744327762688 52.62659906...  \n",
      "1  MULTIPOLYGON (((13.321109641281137 52.52446299...  \n",
      "2  MULTIPOLYGON (((13.579253945950567 52.39083025...  \n",
      "3  MULTIPOLYGON (((13.504807966473637 52.61959821...  \n",
      "4  MULTIPOLYGON (((13.458320351792578 52.48568825...  \n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Neighborhoods Table Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96 entries, 0 to 95\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   district_id      96 non-null     int64 \n",
      " 1   district         96 non-null     object\n",
      " 2   neighborhood_id  96 non-null     int64 \n",
      " 3   neighborhood     96 non-null     object\n",
      " 4   geometry         96 non-null     object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.9+ KB\n",
      "\n",
      "--- Neighborhoods Table Head ---\n",
      "   district_id district  neighborhood_id  neighborhood  \\\n",
      "0     11001001    Mitte              101         Mitte   \n",
      "1     11001001    Mitte              102        Moabit   \n",
      "2     11001001    Mitte              103  Hansaviertel   \n",
      "3     11001001    Mitte              104    Tiergarten   \n",
      "4     11001001    Mitte              105       Wedding   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((13.416490486705102 52.52696152...  \n",
      "1  MULTIPOLYGON (((13.338835973655774 52.51973541...  \n",
      "2  MULTIPOLYGON (((13.343217433986748 52.51556526...  \n",
      "3  MULTIPOLYGON (((13.368793856174213 52.49878098...  \n",
      "4  MULTIPOLYGON (((13.346564518309984 52.53878901...  \n"
     ]
    }
   ],
   "source": [
    "# --- Load the new lookup tables ---\n",
    "\n",
    "districts_path = Path('../source/districts.csv')\n",
    "neighborhoods_path = Path('../source/neighborhoods.csv')\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "districts_df = pd.read_csv(districts_path)\n",
    "neighborhoods_df = pd.read_csv(neighborhoods_path)\n",
    "\n",
    "# --- Inspect the DataFrames ---\n",
    "\n",
    "print(\"--- Districts Table Info ---\")\n",
    "districts_df.info()\n",
    "print(\"\\n--- Districts Table Head ---\")\n",
    "print(districts_df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\") # A separator for clarity\n",
    "\n",
    "print(\"--- Neighborhoods Table Info ---\")\n",
    "neighborhoods_df.info()\n",
    "print(\"\\n--- Neighborhoods Table Head ---\")\n",
    "print(neighborhoods_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484b7f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs have been added successfully! ✅\n",
      "                   district  district_id     neighborhood  neighborhood_id  \\\n",
      "0                     Mitte     11001001            Mitte              101   \n",
      "1                     Mitte     11001001            Mitte              101   \n",
      "2  Friedrichshain-Kreuzberg     11002002   Friedrichshain              201   \n",
      "3  Friedrichshain-Kreuzberg     11002002        Kreuzberg              202   \n",
      "4                    Pankow     11003003  Prenzlauer Berg              301   \n",
      "\n",
      "            suburb  \n",
      "0            Mitte  \n",
      "1            Mitte  \n",
      "2   Friedrichshain  \n",
      "3              NaN  \n",
      "4  Prenzlauer Berg  \n"
     ]
    }
   ],
   "source": [
    "# --- 1. Merge with Districts Table to add 'district_id' ---\n",
    "\n",
    "# We only need the ID and the key from the districts table\n",
    "districts_lookup = districts_df[['district_id', 'district']]\n",
    "\n",
    "# Perform the merge\n",
    "# 'how=\"left\"' keeps all rows from original 'df'\n",
    "df = pd.merge(df, districts_lookup, on='district', how='left')\n",
    "\n",
    "\n",
    "# --- 2. Merge with Neighborhoods Table to add 'neighborhood_id' ---\n",
    "\n",
    "# We only need the ID and the key from the neighborhoods table\n",
    "neighborhoods_lookup = neighborhoods_df[['neighborhood_id', 'neighborhood']]\n",
    "\n",
    "# Perform the second merge\n",
    "df = pd.merge(df, neighborhoods_lookup, on='neighborhood', how='left')\n",
    "\n",
    "\n",
    "# --- 3. Final Check ---\n",
    "print(\"IDs have been added successfully! ✅\")\n",
    "\n",
    "# Display the key columns to verify the result\n",
    "print(df[['district', 'district_id', 'neighborhood', 'neighborhood_id', 'suburb']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da38ebec",
   "metadata": {},
   "source": [
    "I'll drop the 'suburb' column as it's not full and we now have everything we need in the 'neighborhood_id' column. And we can drop the 'district' and 'neighborhood' columns, as there's no need to duplicate them in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a55e7ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 142 entries, 0 to 141\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      142 non-null    object \n",
      " 1   club_name               141 non-null    object \n",
      " 2   phone                   59 non-null     object \n",
      " 3   website                 100 non-null    object \n",
      " 4   wheelchair              89 non-null     object \n",
      " 5   email                   18 non-null     object \n",
      " 6   toilets_wheelchair      36 non-null     object \n",
      " 7   wheelchair_description  11 non-null     object \n",
      " 8   city                    142 non-null    object \n",
      " 9   house_num               108 non-null    object \n",
      " 10  postcode                140 non-null    float64\n",
      " 11  street                  141 non-null    object \n",
      " 12  opening_hours           53 non-null     object \n",
      " 13  live_music              10 non-null     object \n",
      " 14  longitude               142 non-null    float64\n",
      " 15  latitude                142 non-null    float64\n",
      " 16  district_id             142 non-null    int64  \n",
      " 17  neighborhood_id         142 non-null    int64  \n",
      "dtypes: float64(3), int64(2), object(13)\n",
      "memory usage: 20.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=['district', 'neighborhood', 'suburb'], inplace=True, errors='ignore')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1c1ea",
   "metadata": {},
   "source": [
    "We need to change some columns types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1711a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 142 entries, 0 to 141\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      142 non-null    object \n",
      " 1   club_name               141 non-null    object \n",
      " 2   phone                   59 non-null     object \n",
      " 3   website                 100 non-null    object \n",
      " 4   wheelchair              89 non-null     object \n",
      " 5   email                   18 non-null     object \n",
      " 6   toilets_wheelchair      36 non-null     object \n",
      " 7   wheelchair_description  11 non-null     object \n",
      " 8   city                    142 non-null    object \n",
      " 9   house_num               108 non-null    object \n",
      " 10  postcode                140 non-null    object \n",
      " 11  street                  141 non-null    object \n",
      " 12  opening_hours           53 non-null     object \n",
      " 13  live_music              10 non-null     object \n",
      " 14  longitude               142 non-null    float64\n",
      " 15  latitude                142 non-null    float64\n",
      " 16  district_id             142 non-null    object \n",
      " 17  neighborhood_id         142 non-null    object \n",
      "dtypes: float64(2), object(16)\n",
      "memory usage: 20.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# This handles NaNs and removes the .0 from floats\n",
    "df['postcode'] = df['postcode'].astype(pd.Int64Dtype()).astype(str).replace('<NA>', None)\n",
    "\n",
    "# Convert IDs to string\n",
    "df['district_id'] = df['district_id'].astype(str)\n",
    "df['neighborhood_id'] = df['neighborhood_id'].astype(str)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b66c364d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id club_name phone website wheelchair email toilets_wheelchair wheelchair_description    city house_num postcode     street opening_hours live_music  longitude   latitude district_id neighborhood_id\n",
      "134  node/11435535669       NaN   NaN     NaN        NaN   NaN                NaN                    NaN  Berlin       NaN    13347  Seestraße           NaN        NaN  13.354057  52.550957    11001001             105\n"
     ]
    }
   ],
   "source": [
    "# Find rows where 'club_name' is null (NaN)\n",
    "row_with_no_name = df[df['club_name'].isnull()]\n",
    "\n",
    "# .to_string() ensures that all 18 columns are displayed\n",
    "print(row_with_no_name.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fac100",
   "metadata": {},
   "source": [
    "I will drop this row as it lacks the necessary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ebb546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(s) with null 'club_name' have been dropped.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 141 entries, 0 to 141\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      141 non-null    object \n",
      " 1   club_name               141 non-null    object \n",
      " 2   phone                   59 non-null     object \n",
      " 3   website                 100 non-null    object \n",
      " 4   wheelchair              89 non-null     object \n",
      " 5   email                   18 non-null     object \n",
      " 6   toilets_wheelchair      36 non-null     object \n",
      " 7   wheelchair_description  11 non-null     object \n",
      " 8   city                    141 non-null    object \n",
      " 9   house_num               108 non-null    object \n",
      " 10  postcode                139 non-null    object \n",
      " 11  street                  140 non-null    object \n",
      " 12  opening_hours           53 non-null     object \n",
      " 13  live_music              10 non-null     object \n",
      " 14  longitude               141 non-null    float64\n",
      " 15  latitude                141 non-null    float64\n",
      " 16  district_id             141 non-null    object \n",
      " 17  neighborhood_id         141 non-null    object \n",
      "dtypes: float64(2), object(16)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the row(s) where 'club_name' is null \n",
    "index_to_drop = df[df['club_name'].isnull()].index\n",
    "\n",
    "# Drop those rows from the DataFrame\n",
    "# inplace=True modifies the 'df' directly\n",
    "df.drop(index_to_drop, inplace=True)\n",
    "\n",
    "print(\"Row(s) with null 'club_name' have been dropped.\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b79ecc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame successfully saved to '..\\clean\\night_clubs_clean_with_distr.csv'\n"
     ]
    }
   ],
   "source": [
    "#Save the Final Enriched File\n",
    "save_path = Path('../clean/night_clubs_clean_with_distr.csv')\n",
    "df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nDataFrame successfully saved to '{save_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ca8fd",
   "metadata": {},
   "source": [
    "Validation & Quality Checks:\n",
    "  - Check for duplicate rows. \n",
    "  - Check final row count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69824634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd294984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['district_id'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7959cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['neighborhood_id'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "158db2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db38b3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 141 entries, 0 to 141\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      141 non-null    object \n",
      " 1   club_name               141 non-null    object \n",
      " 2   phone                   59 non-null     object \n",
      " 3   website                 100 non-null    object \n",
      " 4   wheelchair              89 non-null     object \n",
      " 5   email                   18 non-null     object \n",
      " 6   toilets_wheelchair      36 non-null     object \n",
      " 7   wheelchair_description  11 non-null     object \n",
      " 8   city                    141 non-null    object \n",
      " 9   house_num               108 non-null    object \n",
      " 10  postcode                139 non-null    object \n",
      " 11  street                  140 non-null    object \n",
      " 12  opening_hours           53 non-null     object \n",
      " 13  live_music              10 non-null     object \n",
      " 14  longitude               141 non-null    float64\n",
      " 15  latitude                141 non-null    float64\n",
      " 16  district_id             141 non-null    object \n",
      " 17  neighborhood_id         141 non-null    object \n",
      "dtypes: float64(2), object(16)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
