{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "306c001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connection engine for the local 'layereddb' is ready.\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sa\n",
    "\n",
    "# Create the connection string for your local database with the new password\n",
    "db_uri = \"postgresql+psycopg2://yana_yelnikova:jPh9p8k6nzjRDe82@localhost:5433/layereddb\"\n",
    "\n",
    "# Create the Engine object, keeping pool_pre_ping for reliability\n",
    "engine = sa.create_engine(db_uri, pool_pre_ping=True)\n",
    "\n",
    "print(\"✅ Connection engine for the local 'layereddb' is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f45e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available schemas in the database:\n",
      "['berlin_labels', 'berlin_recommender', 'berlin_source_data', 'dashboard_data', 'information_schema', 'public']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "# Create an inspector object from engine\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Get the list of schema names\n",
    "schemas = inspector.get_schema_names()\n",
    "\n",
    "print(\"Available schemas in the database:\")\n",
    "print(schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe910b4",
   "metadata": {},
   "source": [
    "We are working in 'berlin_source_data' and 'berlin_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355e547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tables in schema 'berlin_source_data':\n",
      "['theaters', 'pools_refactored', 'district_level_aggregated', 'district_attributes_test', 'bus_tram_stops', 'malls', 'banks', 'social_clubs_activities', 'veterinary_clinics_martin_svitek', 'hospitals_refactored', 'pharmacies', 'supermarkets', 'bike_lanes', 'pools', 'hospitals', 'land_prices', 'test_table_george_smelin', 'gyms', 'universities', 'venues', 'dental_offices', 'post_offices', 'kindergartens', 'sbahn', 'schools', 'short_term_listings', 'districts', 'ubahn', 'long_term_listings', 'veterinary_clinics', 'milieuschutz_protection_zones', 'neighborhoods', 'parks', 'regional_statistics', 'crime_statistics', 'districts_pop_stat', 'playgrounds', 'rent_stats_per_neighborhood']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of table names for the 'berlin_source_data' schema\n",
    "tables_in_schema = inspector.get_table_names(schema='berlin_source_data')\n",
    "\n",
    "# Print the list of tables\n",
    "print(\"\\nTables in schema 'berlin_source_data':\")\n",
    "print(tables_in_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8364de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tables in schema 'berlin_labels':\n",
      "['district_features', 'district_attributes', 'district_labels_new', 'district_features_test', 'district_labels', 'neighborhood_labels']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of table names for the 'berlin_labels' schema\n",
    "tables_in_schema = inspector.get_table_names(schema='berlin_labels')\n",
    "\n",
    "# Print the list of tables\n",
    "print(\"\\nTables in schema 'berlin_labels':\")\n",
    "print(tables_in_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286ed29",
   "metadata": {},
   "source": [
    "Since the 'district_features' table contains all the necessary transport stop counts and the 'district_attributes' table contains the calculated scaling coefficients, I will use these two tables for the labeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ebda3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  district_id  bus_tram_stop_count  uban_station_count  bank_count  \\\n",
      "0    11012012                  254                  10          23   \n",
      "1    11004004                  264                  23          47   \n",
      "2    11009009                  314                   0          24   \n",
      "3    11003003                  292                   3          26   \n",
      "4    11008008                  261                  13          20   \n",
      "\n",
      "   post_office_count  supermarket_count  mall_count  num_sport_clubs  \\\n",
      "0                 15                 90           6               23   \n",
      "1                 38                129           4               20   \n",
      "2                  7                 96           8               47   \n",
      "3                 34                161           8               19   \n",
      "4                 18                119           6               14   \n",
      "\n",
      "   num_gyms  num_pools  \n",
      "0        14         12  \n",
      "1        59         15  \n",
      "2        24         17  \n",
      "3        83          9  \n",
      "4        21          7  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Full table name, including the schema\n",
    "table_name = 'berlin_labels.district_features'\n",
    "\n",
    "# SQL query to select all data (*) from your table\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "# Execute the query and load the result into a Pandas DataFrame\n",
    "# The read_sql function takes an SQL query and a connection object (engine)\n",
    "district_features = pd.read_sql(query, engine)\n",
    "\n",
    "print(district_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c14373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  district_id  area_sq_km  inhabitants  area_coefficient  \\\n",
      "0    11004004   64.662978       343081          0.871208   \n",
      "1    11002002   20.389118       293454          0.274704   \n",
      "2    11011011   52.091363       311881          0.701830   \n",
      "3    11010010   61.782422       291948          0.832398   \n",
      "4    11001001   39.379173       397134          0.530558   \n",
      "\n",
      "   population_coefficient  \n",
      "0                1.061595  \n",
      "1                0.908034  \n",
      "2                0.965053  \n",
      "3                0.903374  \n",
      "4                1.228851  \n"
     ]
    }
   ],
   "source": [
    "# Full table name, including the schema\n",
    "table_name = 'berlin_labels.district_attributes'\n",
    "\n",
    "# SQL query to select all data (*) from your table\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "# Execute the query and load the result into a Pandas DataFrame\n",
    "# The read_sql function takes an SQL query and a connection object (engine)\n",
    "district_attributes = pd.read_sql(query, engine)\n",
    "\n",
    "print(district_attributes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a4002b",
   "metadata": {},
   "source": [
    "We need to calculate AVG for next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14b633fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241.58333333333334 11.0\n"
     ]
    }
   ],
   "source": [
    "avg_bus_tram_stops=district_features['bus_tram_stop_count'].mean()\n",
    "avg_uban_station=district_features['uban_station_count'].mean()\n",
    "print(avg_bus_tram_stops,avg_uban_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28430f18",
   "metadata": {},
   "source": [
    "Now we can use tags #bus_tram_hub, #uban_hub and #public_transport_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c231300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of transport tagging:\n",
      "   district_id          transport_tag\n",
      "1     11004004  #public_transport_hub\n",
      "4     11008008  #public_transport_hub\n",
      "5     11011011          #bus_tram_hub\n",
      "6     11010010          #bus_tram_hub\n",
      "9     11001001  #public_transport_hub\n",
      "10    11002002  #public_transport_hub\n",
      "11    11007007              #uban_hub\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Merge DataFrames ---\n",
    "\n",
    "# Merge the two tables on district_id\n",
    "analysis_df = pd.merge(district_features, district_attributes, on='district_id')\n",
    "\n",
    "\n",
    "# --- Step 2: Calculate \"Hub\" Status ---\n",
    "\n",
    "# Condition for the bus/tram hub\n",
    "is_bus_tram_hub = analysis_df['bus_tram_stop_count'] > (avg_bus_tram_stops * analysis_df['area_coefficient'])\n",
    "\n",
    "# Condition for the U-Bahn hub\n",
    "is_uban_hub = analysis_df['uban_station_count'] > (avg_uban_station * analysis_df['area_coefficient'])\n",
    "\n",
    "\n",
    "# --- Step 3: Apply Hierarchy and Assign Tags ---\n",
    "\n",
    "# Define conditions in order of priority (from strictest to weakest)\n",
    "conditions = [\n",
    "    is_bus_tram_hub & is_uban_hub,  # Condition 1: Is a hub for BOTH transport types\n",
    "    is_bus_tram_hub,                # Condition 2: Is a hub ONLY for bus/tram\n",
    "    is_uban_hub                     # Condition 3: Is a hub ONLY for U-Bahn\n",
    "]\n",
    "\n",
    "# Define the corresponding choices (tags)\n",
    "choices = [\n",
    "    '#public_transport_hub',\n",
    "    '#bus_tram_hub',\n",
    "    '#uban_hub'\n",
    "]\n",
    "\n",
    "# Use numpy.select to assign the tags based on the conditions\n",
    "analysis_df['transport_tag'] = np.select(conditions, choices, default='Not a Hub')\n",
    "\n",
    "\n",
    "# --- Step 4: Display the Result ---\n",
    "print(\"Results of transport tagging:\")\n",
    "# Display only the districts that received a tag\n",
    "print(analysis_df[analysis_df['transport_tag'] != 'Not a Hub'][['district_id', 'transport_tag']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55708bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully uploaded 7 transport tags.\n",
      "\n",
      "Data uploaded to the database:\n",
      "   district_id                  category                  label\n",
      "1     11004004  Mobility & Accessibility  #public_transport_hub\n",
      "4     11008008  Mobility & Accessibility  #public_transport_hub\n",
      "5     11011011  Mobility & Accessibility          #bus_tram_hub\n",
      "6     11010010  Mobility & Accessibility          #bus_tram_hub\n",
      "9     11001001  Mobility & Accessibility  #public_transport_hub\n",
      "10    11002002  Mobility & Accessibility  #public_transport_hub\n",
      "11    11007007  Mobility & Accessibility              #uban_hub\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Format Data for Final Table ---\n",
    "\n",
    "# Filter for rows that actually received a transport tag\n",
    "final_tags_df = analysis_df[analysis_df['transport_tag'] != 'Not a Hub'].copy()\n",
    "\n",
    "# Add the category name manually\n",
    "final_tags_df['category'] = 'Mobility & Accessibility'\n",
    "\n",
    "# Rename 'transport_tag' to 'label' to match the final table structure\n",
    "final_tags_df.rename(columns={'transport_tag': 'label'}, inplace=True)\n",
    "\n",
    "# Select and reorder the columns for the final table\n",
    "final_tags_df = final_tags_df[['district_id', 'category', 'label']]\n",
    "\n",
    "\n",
    "# --- Step 6: Upload to the Database ---\n",
    "\n",
    "# Append the new tags to the existing SQL table\n",
    "try:\n",
    "    final_tags_df.to_sql(\n",
    "        'district_labels_new',\n",
    "        engine,\n",
    "        schema='berlin_labels',\n",
    "        if_exists='append', # Use 'append' to add rows without deleting existing data\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"✅ Successfully uploaded {len(final_tags_df)} transport tags.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An error occurred during upload: {e}\")\n",
    "\n",
    "# Display the data that was just uploaded\n",
    "print(\"\\nData uploaded to the database:\")\n",
    "print(final_tags_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
