{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24ceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connection engine for the local 'layereddb' is ready.\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sa\n",
    "\n",
    "# Create the connection string with placeholders for credentials\n",
    "db_uri = \"postgresql+psycopg2://<USERNAME>:<PASSWORD>@localhost:5433/layereddb\"\n",
    "\n",
    "# Create the Engine object, keeping pool_pre_ping for reliability\n",
    "engine = sa.create_engine(db_uri, pool_pre_ping=True)\n",
    "\n",
    "print(\"✅ Connection engine for the local 'layereddb' is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d9e0d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available schemas in the database:\n",
      "['berlin_labels', 'berlin_recommender', 'berlin_source_data', 'dashboard_data', 'information_schema', 'public']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "# Create an inspector object from engine\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Get the list of schema names\n",
    "schemas = inspector.get_schema_names()\n",
    "\n",
    "print(\"Available schemas in the database:\")\n",
    "print(schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8266395",
   "metadata": {},
   "source": [
    "We are working in 'berlin_source_data' and 'berlin_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a14b4b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tables in schema 'berlin_source_data':\n",
      "['theaters', 'pools_refactored', 'theaters_backup_neigh_final', 'night_clubs', 'district_level_aggregated', 'bus_tram_stops', 'malls', 'banks', 'doctors', 'social_clubs_activities', 'veterinary_clinics_martin_svitek', 'hospitals_refactored', 'pharmacies', 'supermarkets', 'bike_lanes', 'pools', 'hospitals', 'land_prices', 'test_table_george_smelin', 'venues', 'gyms', 'universities', 'dental_offices', 'post_offices', 'kindergartens', 'sbahn', 'schools', 'short_term_listings', 'districts', 'ubahn', 'long_term_listings', 'veterinary_clinics', 'milieuschutz_protection_zones', 'neighborhoods', 'parks', 'regional_statistics', 'crime_statistics', 'districts_pop_stat', 'playgrounds', 'rent_stats_per_neighborhood']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of table names for the 'berlin_source_data' schema\n",
    "tables_in_schema = inspector.get_table_names(schema='berlin_source_data')\n",
    "\n",
    "# Print the list of tables\n",
    "print(\"\\nTables in schema 'berlin_source_data':\")\n",
    "print(tables_in_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "96b77f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tables in schema 'berlin_labels':\n",
      "['district_attributes', 'district_labels_new', 'district_features', 'district_labels', 'neighborhood_labels']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of table names for the 'berlin_labels' schema\n",
    "tables_in_schema = inspector.get_table_names(schema='berlin_labels')\n",
    "\n",
    "# Print the list of tables\n",
    "print(\"\\nTables in schema 'berlin_labels':\")\n",
    "print(tables_in_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001de552",
   "metadata": {},
   "source": [
    "Since the 'district_features' table contains all the necessary counts for my labels and the 'district_attributes' table contains the calculated scaling coefficients, I will use these two tables for the labeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1ade998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  district_id  bus_tram_stop_count  uban_station_count  sbahn_station_count  \\\n",
      "0    11001001                  222                  32                   45   \n",
      "1    11002002                  120                  15                   20   \n",
      "2    11003003                  292                   3                   37   \n",
      "3    11004004                  264                  23                   37   \n",
      "4    11005005                  283                   5                    3   \n",
      "\n",
      "   bank_count  post_office_count  supermarket_count  mall_count  \\\n",
      "0          48                 40                146          13   \n",
      "1          21                 28                107           4   \n",
      "2          26                 34                161           8   \n",
      "3          47                 38                129           4   \n",
      "4          19                  1                 77           5   \n",
      "\n",
      "   num_sport_clubs  num_gyms  num_pools  hospital_count  pharmacy_count  \\\n",
      "0               15        63          9              46              75   \n",
      "1               21        58          8              15              46   \n",
      "2               19        83          9              24              64   \n",
      "3               20        59         15              31              88   \n",
      "4               27         9         17               9              41   \n",
      "\n",
      "   dental_office_count  total_crime_cases_latest_year  \\\n",
      "0                   82                          71652   \n",
      "1                   57                         256856   \n",
      "2                   93                         173850   \n",
      "3                  136                         233294   \n",
      "4                   16                         115046   \n",
      "\n",
      "   evening_venue_count_9pm_11pm  late_venue_count_after_11pm  \\\n",
      "0                           386                          215   \n",
      "1                           312                          214   \n",
      "2                           247                          117   \n",
      "3                           334                          165   \n",
      "4                            73                           27   \n",
      "\n",
      "   night_club_count  restaurant_count  bar_count  cafe_count  bike_lane_count  \\\n",
      "0                43               903        236         540             7552   \n",
      "1                46               720        167         392             4682   \n",
      "2                 8               491        107         282             6693   \n",
      "3                16               753         76         391             7991   \n",
      "4                 1               160          8          54             3362   \n",
      "\n",
      "   total_bike_lane_km  num_culture_places  num_art_places  num_music_places  \\\n",
      "0          460.034537                 181            80.0              26.0   \n",
      "1          248.631691                 137            58.0              31.0   \n",
      "2          710.968710                 105            27.0              42.0   \n",
      "3          576.164550                  98            42.0              24.0   \n",
      "4          412.914880                  47             5.0               3.0   \n",
      "\n",
      "   total_primary_adult_score  total_pediatric_score  specialist_score_total  \n",
      "0                       55.8                   22.2                   259.0  \n",
      "1                       53.5                    8.0                   126.4  \n",
      "2                       93.3                   17.4                   187.2  \n",
      "3                       77.3                   15.8                   241.2  \n",
      "4                       13.7                    5.7                    67.6  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Full table name, including the schema\n",
    "table_name = 'berlin_labels.district_features'\n",
    "\n",
    "# SQL query to select all data (*) from your table\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "# Execute the query and load the result into a Pandas DataFrame\n",
    "# The read_sql function takes an SQL query and a connection object (engine)\n",
    "district_features = pd.read_sql(query, engine)\n",
    "\n",
    "print(district_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c27efcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  district_id  area_sq_km  inhabitants  area_coefficient  \\\n",
      "0    11004004   64.662978       343081          0.871208   \n",
      "1    11002002   20.389118       293454          0.274704   \n",
      "2    11011011   52.091363       311881          0.701830   \n",
      "3    11010010   61.782422       291948          0.832398   \n",
      "4    11001001   39.379173       397134          0.530558   \n",
      "\n",
      "   population_coefficient  \n",
      "0                1.061595  \n",
      "1                0.908034  \n",
      "2                0.965053  \n",
      "3                0.903374  \n",
      "4                1.228851  \n"
     ]
    }
   ],
   "source": [
    "# Full table name, including the schema\n",
    "table_name = 'berlin_labels.district_attributes'\n",
    "\n",
    "# SQL query to select all data (*) from your table\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "# Execute the query and load the result into a Pandas DataFrame\n",
    "# The read_sql function takes an SQL query and a connection object (engine)\n",
    "district_attributes = pd.read_sql(query, engine)\n",
    "\n",
    "print(district_attributes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3e623cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.916666666666668 56.25 65.08333333333333 53.025 11.725 149.52499999999998\n"
     ]
    }
   ],
   "source": [
    "avg_hospitals=district_features['hospital_count'].mean()\n",
    "avg_pharmacys=district_features['pharmacy_count'].mean()\n",
    "avg_dental_offices=district_features['dental_office_count'].mean()\n",
    "avg_primary_adult=district_features['total_primary_adult_score'].mean()\n",
    "avg_pediatric=district_features['total_pediatric_score'].mean()\n",
    "avg_specialist=district_features['specialist_score_total'].mean()\n",
    "  \n",
    "print(avg_hospitals, avg_pharmacys, avg_dental_offices, avg_primary_adult, avg_pediatric, avg_specialist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077a72a",
   "metadata": {},
   "source": [
    "I would like to add the label #sunday_pharmacy_access for districts that have at least one pharmacy regularly open on Sundays (excluding the emergency pharmacies that rotate weekly). To do this, I need to filter the pharmacies table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fca01bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 675 pharmacy records.\n",
      "\n",
      "Pharmacies open on Sunday (filtered):\n",
      "    pharmacy_id district_id                                       openinghours\n",
      "151   419545768    11001001                  mo-sa 08:30-22:30; su 10:00-22:30\n",
      "259   638953355    11011011  mo-fr 08:00-19:00; sa 08:00-13:00; su 08:00-16:00\n",
      "396  1552051348    11001001                                  mo-su 08:00-24:00\n",
      "440  2098147261    11006006                  mo-sa 08:30-19:00; su 08:30-14:00\n",
      "515  3350477701    11001001  mo-fr 08:00-20:00; su 10:00-16:00; sa 09:00-19:00\n",
      "604  6006371223    11003003  mo-fr 08:30-19:00; sa 08:30-20:00; su 10:00-20:00\n",
      "663    59806041    11001001                                  mo-su 07:00-21:00\n",
      "666   337165575    11002002                  mo-sa 08:00-20:00; su 10:00-18:00\n",
      "668   381240714    11007007  mo-fr 07:00-20:00; sa 09:00-19:00; su 10:00-18:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# LOAD THE 'PHARMACIES' DATAFRAME FROM THE DATABASE\n",
    "\n",
    "PHARMACY_TABLE = 'berlin_source_data.pharmacies' \n",
    "query = f\"SELECT pharmacy_id, district_id, openinghours FROM {PHARMACY_TABLE}\"\n",
    "\n",
    "try:\n",
    "    pharmacies = pd.read_sql(query, engine) \n",
    "    print(f\"Successfully loaded {len(pharmacies)} pharmacy records.\")\n",
    "except NameError:\n",
    "    print(\"Error: 'engine' object is not defined. Please initialize your database connection.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during database query: {e}\")\n",
    "    \n",
    "# 1. Create the NEW regex pattern\n",
    "pattern = r'(?:\\b(?:su|so)\\s*\\d)|(?:[a-z-]{2,}-\\s*(?:su|so)\\b\\s*\\d)'\n",
    "\n",
    "\n",
    "# 2. Apply the filter (case=False is mandatory)\n",
    "# Check if the dataframe was successfully loaded and the column exists\n",
    "if 'openinghours' in pharmacies.columns:\n",
    "    mask = pharmacies['openinghours'].str.contains(pattern, case=False, na=False)\n",
    "\n",
    "    # 3. Get the DataFrame of pharmacies open on Sunday\n",
    "    sunday_pharmacies = pharmacies[mask].copy() # Use .copy() to prevent SettingWithCopyWarning\n",
    "\n",
    "    # 4. Print only the necessary columns\n",
    "    columns_to_show = ['pharmacy_id', 'district_id', 'openinghours']\n",
    "\n",
    "    if all(col in sunday_pharmacies.columns for col in columns_to_show):\n",
    "        print(\"\\nPharmacies open on Sunday (filtered):\")\n",
    "        print(sunday_pharmacies[columns_to_show].head(10))\n",
    "    else:\n",
    "        print(f\"Error: Columns {columns_to_show} not found in the filtered result.\")\n",
    "        print(\"Result with all columns:\")\n",
    "        print(sunday_pharmacies)\n",
    "else:\n",
    "    print(\"\\nAborting filter: 'pharmacies' DataFrame was not loaded correctly or 'openinghours' column is missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d51e2d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "district_id\n",
      "11001001    4\n",
      "11002002    1\n",
      "11003003    1\n",
      "11006006    1\n",
      "11007007    1\n",
      "11011011    1\n",
      "Name: pharmacy_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sunday_pharmacies_count=sunday_pharmacies.groupby('district_id')['pharmacy_id'].nunique()\n",
    "print(sunday_pharmacies_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8b2eda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis_df created successfully by merging the tables.\n"
     ]
    }
   ],
   "source": [
    "# Merge the DataFrames to create analysis_df\n",
    "analysis_df = pd.merge(district_features, district_attributes, on='district_id')\n",
    "\n",
    "print(\"analysis_df created successfully by merging the tables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3a281e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verification of #sunday_pharmacy_access Tag Assignment ---\n",
      "   district_id  sunday_pharmacy_count      sunday_pharmacy_tag\n",
      "0     11001001                      4  #sunday_pharmacy_access\n",
      "1     11002002                      1  #sunday_pharmacy_access\n",
      "2     11003003                      1  #sunday_pharmacy_access\n",
      "5     11006006                      1  #sunday_pharmacy_access\n",
      "6     11007007                      1  #sunday_pharmacy_access\n",
      "10    11011011                      1  #sunday_pharmacy_access\n",
      "\n",
      " Tag #sunday_pharmacy_access created and integrated as a boolean column.\n",
      "Total districts tagged: 6\n"
     ]
    }
   ],
   "source": [
    "# Ensure district_id is a column, not an index, in analysis_df\n",
    "if analysis_df.index.name == 'district_id':\n",
    "    analysis_df = analysis_df.reset_index()\n",
    "\n",
    "# Merge the count of Sunday pharmacies. Rename the merged column and fill NaNs with 0.\n",
    "analysis_df = pd.merge(\n",
    "    analysis_df, \n",
    "    sunday_pharmacies_count.rename('sunday_pharmacy_count'), \n",
    "    on='district_id', \n",
    "    how='left'\n",
    ").fillna({'sunday_pharmacy_count': 0}) # Fill only the new count column\n",
    "\n",
    "\n",
    "#  Assign the final boolean tag directly to the main DataFrame\n",
    "analysis_df['#sunday_pharmacy_access'] = analysis_df['sunday_pharmacy_count'] > 0\n",
    "\n",
    "\n",
    "display_df = analysis_df[analysis_df['#sunday_pharmacy_access']].copy()\n",
    "\n",
    "if not display_df.empty:\n",
    "    display_df['sunday_pharmacy_tag'] = '#sunday_pharmacy_access'\n",
    "    print(\"\\n--- Verification of #sunday_pharmacy_access Tag Assignment ---\")\n",
    "    print(\n",
    "        display_df[['district_id', 'sunday_pharmacy_count', 'sunday_pharmacy_tag']]\n",
    "        .assign(sunday_pharmacy_count=lambda x: x['sunday_pharmacy_count'].astype(int))\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nNo districts received the #sunday_pharmacy_access tag.\")\n",
    "\n",
    "\n",
    "# Cleanup (Removing the intermediate count column)\n",
    "\n",
    "analysis_df.drop(columns=['sunday_pharmacy_count'], inplace=True)\n",
    "\n",
    "print(\"\\n Tag #sunday_pharmacy_access created and integrated as a boolean column.\")\n",
    "print(f\"Total districts tagged: {analysis_df['#sunday_pharmacy_access'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901d87a",
   "metadata": {},
   "source": [
    "The independent access tag (#sunday_pharmacy_access) has been successfully assigned. This final block executes the multi-layered tagging logic for the \"Amenities & Services\" category.\n",
    "\n",
    "It computes all composite tags (Tier 2 and Tier 3), applies the full hierarchical cleanup, and transforms the resulting boolean assignments into the long (district_id, tag_name) format required for bulk insertion into the `berlin_labels.district_labels_new` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "db47802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " FINAL Amenities & Services Tag Assignment Complete \n",
      "Total districts with Full Spectrum tag: 2\n",
      "\n",
      "--- FINAL LIST OF ASSIGNED TAGS FOR DB UPLOAD (district_id, tag_name) ---\n",
      "    district_id                       label              category\n",
      "2      11003003      #core_primary_care_hub  Amenities & Services\n",
      "6      11007007      #core_primary_care_hub  Amenities & Services\n",
      "7      11008008      #core_primary_care_hub  Amenities & Services\n",
      "15     11004004   #full_spectrum_healthcare  Amenities & Services\n",
      "17     11006006   #full_spectrum_healthcare  Amenities & Services\n",
      "24     11001001      #high_hospital_density  Amenities & Services\n",
      "25     11002002      #high_hospital_density  Amenities & Services\n",
      "33     11010010      #high_hospital_density  Amenities & Services\n",
      "34     11011011      #high_hospital_density  Amenities & Services\n",
      "36     11001001        #many_dental_clinics  Amenities & Services\n",
      "38     11003003        #many_dental_clinics  Amenities & Services\n",
      "42     11007007        #many_dental_clinics  Amenities & Services\n",
      "48     11001001            #many_pharmacies  Amenities & Services\n",
      "54     11007007            #many_pharmacies  Amenities & Services\n",
      "60     11001001             #specialist_hub  Amenities & Services\n",
      "66     11007007             #specialist_hub  Amenities & Services\n",
      "72     11001001      #strong_pediatric_care  Amenities & Services\n",
      "85     11002002  #strong_primary_adult_care  Amenities & Services\n",
      "92     11009009  #strong_primary_adult_care  Amenities & Services\n",
      "96     11001001     #sunday_pharmacy_access  Amenities & Services\n",
      "97     11002002     #sunday_pharmacy_access  Amenities & Services\n",
      "98     11003003     #sunday_pharmacy_access  Amenities & Services\n",
      "101    11006006     #sunday_pharmacy_access  Amenities & Services\n",
      "102    11007007     #sunday_pharmacy_access  Amenities & Services\n",
      "106    11011011     #sunday_pharmacy_access  Amenities & Services\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS DEFINITION\n",
    "\n",
    "POP_COEFF_COLUMN = 'population_coefficient' \n",
    "AREA_COEFF_COLUMN = 'area_coefficient'\n",
    "HOSPITAL_COUNT_COLUMN = 'hospital_count'\n",
    "PHARMACY_COUNT_COLUMN = 'pharmacy_count'\n",
    "DENTAL_COUNT_COLUMN = 'dental_office_count'\n",
    "\n",
    "\n",
    "# APPLY LOGIC FOR ALL INDIVIDUAL (BASE) TAGS \n",
    "\n",
    "# Score-Based Tags (using POPULATION Coefficient)\n",
    "analysis_df['#strong_primary_adult_care'] = (\n",
    "    analysis_df['total_primary_adult_score'] > \n",
    "    (avg_primary_adult * analysis_df[POP_COEFF_COLUMN]) \n",
    ")\n",
    "analysis_df['#strong_pediatric_care'] = (\n",
    "    analysis_df['total_pediatric_score'] > \n",
    "    (avg_pediatric * analysis_df[POP_COEFF_COLUMN]) \n",
    ")\n",
    "analysis_df['#specialist_hub'] = (\n",
    "    analysis_df['specialist_score_total'] > \n",
    "    (avg_specialist * analysis_df[POP_COEFF_COLUMN]) \n",
    ")\n",
    "\n",
    "# Count-Based Tags (using AREA or POPULATION Coefficient)\n",
    "analysis_df['#high_hospital_density'] = (\n",
    "    analysis_df[HOSPITAL_COUNT_COLUMN] > \n",
    "    (avg_hospitals * analysis_df[AREA_COEFF_COLUMN]) \n",
    ")\n",
    "analysis_df['#many_pharmacies'] = (\n",
    "    analysis_df[PHARMACY_COUNT_COLUMN] > \n",
    "    (avg_pharmacys * analysis_df[POP_COEFF_COLUMN]) \n",
    ")\n",
    "analysis_df['#many_dental_clinics'] = (\n",
    "    analysis_df[DENTAL_COUNT_COLUMN] > \n",
    "    (avg_dental_offices * analysis_df[POP_COEFF_COLUMN]) \n",
    ")\n",
    "\n",
    "# CREATE COMPOSITE TAGS AND APPLY HIERARCHY\n",
    "\n",
    "# Composite 1: Core Primary Care Hub (Tier 2)\n",
    "# Replaces #strong_primary_adult_care AND #strong_pediatric_care\n",
    "analysis_df['#core_primary_care_hub'] = (\n",
    "    analysis_df['#strong_primary_adult_care'] & \n",
    "    analysis_df['#strong_pediatric_care']\n",
    ")\n",
    "\n",
    "\n",
    "# Composite 2: Full Spectrum Healthcare (Tier 3 - TOP TIER)\n",
    "# Replaces ALL Tier 1 & 2 components below it\n",
    "analysis_df['#full_spectrum_healthcare'] = (\n",
    "    analysis_df['#core_primary_care_hub'] & \n",
    "    analysis_df['#specialist_hub'] & \n",
    "    analysis_df['#many_pharmacies'] & \n",
    "    analysis_df['#many_dental_clinics'] & \n",
    "    analysis_df['#high_hospital_density']\n",
    ")\n",
    "\n",
    "\n",
    "# APPLY HIERARCHICAL CLEANUP (REPLACEMENT)\n",
    "\n",
    "# Tags that are suppressed by the higher-level tags:\n",
    "tags_to_suppress_by_core_hub = ['#strong_primary_adult_care', '#strong_pediatric_care']\n",
    "\n",
    "tags_to_suppress_by_full_spectrum = [\n",
    "    '#core_primary_care_hub', \n",
    "    '#specialist_hub', \n",
    "    '#many_pharmacies', \n",
    "    '#many_dental_clinics', \n",
    "    '#high_hospital_density'\n",
    "]\n",
    "\n",
    "# Replacement 1: If #core_primary_care_hub is TRUE, suppress its two components\n",
    "analysis_df.loc[analysis_df['#core_primary_care_hub'], tags_to_suppress_by_core_hub] = False\n",
    "\n",
    "# Replacement 2: If #full_spectrum_healthcare is TRUE, suppress ALL lower tags (Tier 1 & Tier 2)\n",
    "analysis_df.loc[analysis_df['#full_spectrum_healthcare'], tags_to_suppress_by_full_spectrum] = False\n",
    "\n",
    "\n",
    "# FINAL VERIFICATION & ETL TRANSFORMATION\n",
    "\n",
    "all_tags = tags_to_suppress_by_full_spectrum + tags_to_suppress_by_core_hub + ['#full_spectrum_healthcare', '#sunday_pharmacy_access']\n",
    "# Remove duplicates caused by merging lists\n",
    "final_tags_list = sorted(list(set(all_tags))) \n",
    "\n",
    "print(\"\\n FINAL Amenities & Services Tag Assignment Complete \")\n",
    "print(f\"Total districts with Full Spectrum tag: {analysis_df['#full_spectrum_healthcare'].sum()}\")\n",
    "\n",
    "\n",
    "# ETL FINAL STEP: TRANSFORM TO LONG FORMAT (FOR DB UPLOAD) \n",
    "\n",
    "# Select only the district_id and the final list of boolean tag columns\n",
    "df_tags_only = analysis_df[['district_id'] + final_tags_list].copy()\n",
    "\n",
    "# Convert the boolean columns into a \"long\" format (melt)\n",
    "df_long = df_tags_only.melt(\n",
    "    id_vars=['district_id'],\n",
    "    value_vars=final_tags_list,\n",
    "    var_name='label',          \n",
    "    value_name='is_assigned'   \n",
    ")\n",
    "\n",
    "# Filter for only the assigned tags (where value is True)\n",
    "df_final_upload = df_long[df_long['is_assigned'] == True].copy()\n",
    "\n",
    "# Cleanup for upload: Select only the district_id and the tag name (label)\n",
    "df_final_upload = df_final_upload[['district_id', 'label']]\n",
    "df_final_upload['category'] = 'Amenities & Services' # Add the category column\n",
    "\n",
    "print(\"\\n--- FINAL LIST OF ASSIGNED TAGS FOR DB UPLOAD (district_id, tag_name) ---\")\n",
    "print(df_final_upload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f139055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Success! 25 tags successfully uploaded to the database.\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS FOR DB UPLOAD \n",
    "TARGET_TABLE = 'district_labels_new'\n",
    "TARGET_SCHEMA = 'berlin_labels'\n",
    "\n",
    "try:\n",
    "    # Check if the 'engine' object is available\n",
    "    if 'engine' not in locals() and 'engine' not in globals():\n",
    "        raise NameError(\"The 'engine' object for database connection is not defined.\")\n",
    "\n",
    "    # Upload the data\n",
    "    # We use if_exists='append' to add the new tags without deleting existing data\n",
    "    df_final_upload.to_sql(\n",
    "        name=TARGET_TABLE,\n",
    "        con=engine,\n",
    "        schema=TARGET_SCHEMA,\n",
    "        if_exists='append',\n",
    "        index=False  # Do not upload the DataFrame index as a column\n",
    "    )\n",
    "\n",
    "    print(f\" Success! {len(df_final_upload)} tags successfully uploaded to the database.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Fatal Error: {e}. Please ensure your SQLAlchemy 'engine' object is initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during database upload: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
