{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53777b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connection engine for the local 'layereddb' is ready.\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sa\n",
    "\n",
    "# Create the connection string for your local database with the new password\n",
    "db_uri = \"postgresql+psycopg2://yana_yelnikova:jPh9p8k6nzjRDe82@localhost:5433/layereddb\"\n",
    "\n",
    "# Create the Engine object, keeping pool_pre_ping for reliability\n",
    "engine = sa.create_engine(db_uri, pool_pre_ping=True)\n",
    "\n",
    "print(\"✅ Connection engine for the local 'layereddb' is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847d27f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available schemas in the database:\n",
      "['berlin_labels', 'berlin_recommender', 'berlin_source_data', 'dashboard_data', 'information_schema', 'public']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "# Create an inspector object from engine\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Get the list of schema names\n",
    "schemas = inspector.get_schema_names()\n",
    "\n",
    "print(\"Available schemas in the database:\")\n",
    "print(schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e5728",
   "metadata": {},
   "source": [
    "We are working in 'berlin_source_data' and 'berlin_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b29e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tables in schema 'berlin_source_data':\n",
      "['theaters', 'pools_refactored', 'district_level_aggregated', 'district_attributes_test', 'bus_tram_stops', 'malls', 'banks', 'social_clubs_activities', 'veterinary_clinics_martin_svitek', 'hospitals_refactored', 'pharmacies', 'supermarkets', 'bike_lanes', 'pools', 'hospitals', 'land_prices', 'test_table_george_smelin', 'gyms', 'universities', 'venues', 'dental_offices', 'post_offices', 'kindergartens', 'sbahn', 'schools', 'short_term_listings', 'districts', 'ubahn', 'long_term_listings', 'veterinary_clinics', 'milieuschutz_protection_zones', 'neighborhoods', 'parks', 'regional_statistics', 'crime_statistics', 'districts_pop_stat', 'playgrounds', 'rent_stats_per_neighborhood']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of table names for the 'berlin_source_data' schema\n",
    "tables_in_schema = inspector.get_table_names(schema='berlin_source_data')\n",
    "\n",
    "# Print the list of tables\n",
    "print(\"\\nTables in schema 'berlin_source_data':\")\n",
    "print(tables_in_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a2d8f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tables in schema 'berlin_labels':\n",
      "['district_features', 'district_attributes', 'district_labels_new', 'district_features_test', 'district_labels', 'neighborhood_labels']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of table names for the 'berlin_labels' schema\n",
    "tables_in_schema = inspector.get_table_names(schema='berlin_labels')\n",
    "\n",
    "# Print the list of tables\n",
    "print(\"\\nTables in schema 'berlin_labels':\")\n",
    "print(tables_in_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c7cff",
   "metadata": {},
   "source": [
    "Since the 'district_features' table contains all the necessary transport stop counts and the 'district_attributes' table contains the calculated scaling coefficients, I will use these two tables for the labeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e828412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  district_id  bus_tram_stop_count  uban_station_count  bank_count  \\\n",
      "0    11012012                  254                  10          23   \n",
      "1    11004004                  264                  23          47   \n",
      "2    11009009                  314                   0          24   \n",
      "3    11003003                  292                   3          26   \n",
      "4    11008008                  261                  13          20   \n",
      "\n",
      "   post_office_count  supermarket_count  mall_count  num_sport_clubs  \\\n",
      "0                 15                 90           6               23   \n",
      "1                 38                129           4               20   \n",
      "2                  7                 96           8               47   \n",
      "3                 34                161           8               19   \n",
      "4                 18                119           6               14   \n",
      "\n",
      "   num_gyms  num_pools  \n",
      "0        14         12  \n",
      "1        59         15  \n",
      "2        24         17  \n",
      "3        83          9  \n",
      "4        21          7  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Full table name, including the schema\n",
    "table_name = 'berlin_labels.district_features'\n",
    "\n",
    "# SQL query to select all data (*) from your table\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "# Execute the query and load the result into a Pandas DataFrame\n",
    "# The read_sql function takes an SQL query and a connection object (engine)\n",
    "district_features = pd.read_sql(query, engine)\n",
    "\n",
    "print(district_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7277a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  district_id  area_sq_km  inhabitants  area_coefficient  \\\n",
      "0    11004004   64.662978       343081          0.871208   \n",
      "1    11002002   20.389118       293454          0.274704   \n",
      "2    11011011   52.091363       311881          0.701830   \n",
      "3    11010010   61.782422       291948          0.832398   \n",
      "4    11001001   39.379173       397134          0.530558   \n",
      "\n",
      "   population_coefficient  \n",
      "0                1.061595  \n",
      "1                0.908034  \n",
      "2                0.965053  \n",
      "3                0.903374  \n",
      "4                1.228851  \n"
     ]
    }
   ],
   "source": [
    "# Full table name, including the schema\n",
    "table_name = 'berlin_labels.district_attributes'\n",
    "\n",
    "# SQL query to select all data (*) from your table\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "# Execute the query and load the result into a Pandas DataFrame\n",
    "# The read_sql function takes an SQL query and a connection object (engine)\n",
    "district_attributes = pd.read_sql(query, engine)\n",
    "\n",
    "print(district_attributes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f2b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.916666666666668 20.333333333333332 112.91666666666667 8.666666666666666\n"
     ]
    }
   ],
   "source": [
    "avg_banks=district_features['bank_count'].mean()\n",
    "avg_post_offices=district_features['post_office_count'].mean()\n",
    "avg_supermarkets=district_features['supermarket_count'].mean()\n",
    "avg_malls=district_features['mall_count'].mean()\n",
    "  \n",
    "print(avg_banks,avg_post_offices, avg_supermarkets, avg_malls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "170abf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results from Part 1 (Convenience Tags) ---\n",
      "   district_id              category                label\n",
      "1     11004004  Amenities & Services   #highly_convenient\n",
      "3     11003003  Amenities & Services   #daily_convenience\n",
      "4     11008008  Amenities & Services  #commercial_hotspot\n",
      "5     11011011  Amenities & Services   #daily_convenience\n",
      "9     11001001  Amenities & Services  #commercial_hotspot\n",
      "10    11002002  Amenities & Services  #commercial_hotspot\n",
      "11    11007007  Amenities & Services   #highly_convenient\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Merge DataFrames ---\n",
    "# Assuming 'district_features' and 'district_attributes' are already loaded\n",
    "analysis_df = pd.merge(district_features, district_attributes, on='district_id')\n",
    "\n",
    "# --- Step 2: Calculate \"Hub\" Statuses ---\n",
    "# Assuming all average counts (avg_banks, etc.) are already calculated\n",
    "is_bank_hub = analysis_df['bank_count'] > (avg_banks * analysis_df['area_coefficient'])\n",
    "is_post_hub = analysis_df['post_office_count'] > (avg_post_offices * analysis_df['area_coefficient'])\n",
    "is_supermarket_hub = analysis_df['supermarket_count'] > (avg_supermarkets * analysis_df['area_coefficient'])\n",
    "is_mall_hub = analysis_df['mall_count'] > (avg_malls * analysis_df['area_coefficient'])\n",
    "\n",
    "# --- Step 3: Calculate Convenience Score (0-3) ---\n",
    "# The score is based ONLY on the three core amenities\n",
    "analysis_df['convenience_score'] = (is_bank_hub.astype(int) + \n",
    "                                    is_post_hub.astype(int) + \n",
    "                                    is_supermarket_hub.astype(int))\n",
    "\n",
    "# --- Step 4: Apply Hierarchy for Convenience Tags ---\n",
    "# Define conditions in order of priority\n",
    "conditions = [\n",
    "    (analysis_df['convenience_score'] == 3) & is_mall_hub, # Condition for #commercial_hotspot\n",
    "    (analysis_df['convenience_score'] == 3),               # Condition for #highly_convenient\n",
    "    (analysis_df['convenience_score'] == 2)                # Condition for #daily_convenience\n",
    "]\n",
    "\n",
    "# Define the corresponding tags\n",
    "choices = [\n",
    "    '#commercial_hotspot',\n",
    "    '#highly_convenient',\n",
    "    '#daily_convenience'\n",
    "]\n",
    "\n",
    "# Assign the single best convenience tag\n",
    "analysis_df['convenience_tag'] = np.select(conditions, choices, default='Not Tagged')\n",
    "\n",
    "# --- Step 5: Format the result of Part 1 ---\n",
    "convenience_tags_df = analysis_df[analysis_df['convenience_tag'] != 'Not Tagged'].copy()\n",
    "convenience_tags_df['category'] = 'Amenities & Services'\n",
    "convenience_tags_df.rename(columns={'convenience_tag': 'label'}, inplace=True)\n",
    "convenience_tags_df = convenience_tags_df[['district_id', 'category', 'label']]\n",
    "\n",
    "print(\"--- Results from Part 1 (Convenience Tags) ---\")\n",
    "print(convenience_tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eecf6335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results from Part 2 (Shopping Tag) ---\n",
      "   district_id              category                  label\n",
      "5     11011011  Amenities & Services  #shopping_destination\n",
      "6     11010010  Amenities & Services  #shopping_destination\n",
      "9     11001001  Amenities & Services  #shopping_destination\n",
      "10    11002002  Amenities & Services  #shopping_destination\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Define the Stricter Threshold for Malls ---\n",
    "mall_threshold = avg_malls * analysis_df['area_coefficient'] * 1.5\n",
    "\n",
    "# --- Step 2: Check if a district is a shopping destination ---\n",
    "is_shopping_destination = analysis_df['mall_count'] > mall_threshold\n",
    "\n",
    "# --- Step 3: Assign the tag ---\n",
    "analysis_df['shopping_tag'] = np.where(is_shopping_destination, '#shopping_destination', 'Not Tagged')\n",
    "\n",
    "# --- Step 4: Format the result of Part 2 ---\n",
    "shopping_tags_df = analysis_df[analysis_df['shopping_tag'] != 'Not Tagged'].copy()\n",
    "shopping_tags_df['category'] = 'Amenities & Services'\n",
    "shopping_tags_df.rename(columns={'shopping_tag': 'label'}, inplace=True)\n",
    "shopping_tags_df = shopping_tags_df[['district_id', 'category', 'label']]\n",
    "\n",
    "print(\"\\n--- Results from Part 2 (Shopping Tag) ---\")\n",
    "print(shopping_tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "167b5ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Combined Tags for Upload ---\n",
      "   district_id              category                  label\n",
      "0     11004004  Amenities & Services     #highly_convenient\n",
      "1     11003003  Amenities & Services     #daily_convenience\n",
      "2     11008008  Amenities & Services    #commercial_hotspot\n",
      "3     11011011  Amenities & Services     #daily_convenience\n",
      "4     11001001  Amenities & Services    #commercial_hotspot\n",
      "5     11002002  Amenities & Services    #commercial_hotspot\n",
      "6     11007007  Amenities & Services     #highly_convenient\n",
      "7     11011011  Amenities & Services  #shopping_destination\n",
      "8     11010010  Amenities & Services  #shopping_destination\n",
      "9     11001001  Amenities & Services  #shopping_destination\n",
      "10    11002002  Amenities & Services  #shopping_destination\n",
      "\n",
      "✅ Successfully uploaded 11 amenity tags.\n"
     ]
    }
   ],
   "source": [
    "# --- Combine both sets of tags into one final DataFrame ---\n",
    "final_tags_df = pd.concat([convenience_tags_df, shopping_tags_df], ignore_index=True)\n",
    "\n",
    "print(\"\\n--- Final Combined Tags for Upload ---\")\n",
    "print(final_tags_df)\n",
    "\n",
    "# --- Upload to the Database ---\n",
    "try:\n",
    "    final_tags_df.to_sql(\n",
    "        'district_labels_new',\n",
    "        engine,\n",
    "        schema='berlin_labels',\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"\\n✅ Successfully uploaded {len(final_tags_df)} amenity tags.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ An error occurred during upload: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
